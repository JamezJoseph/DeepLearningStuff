{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesjoseph/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from keras import models, layers,utils,optimizers\n",
    "from keras.utils import to_categorical,normalize\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten,Dense,Dropout\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(xtrain,ytrain),(xtest,ytest)=cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=normalize(xtrain,axis=1)\n",
    "xtest=normalize(xtest,axis=1)\n",
    "ytrain=to_categorical(ytrain,10)\n",
    "ytest=to_categorical(ytest,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.1871 - loss: 2.1909 - val_accuracy: 0.2915 - val_loss: 2.0064\n",
      "Epoch 2/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2885 - loss: 1.9839 - val_accuracy: 0.3249 - val_loss: 1.9032\n",
      "Epoch 3/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3316 - loss: 1.8759 - val_accuracy: 0.3452 - val_loss: 1.8423\n",
      "Epoch 4/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3615 - loss: 1.8177 - val_accuracy: 0.3570 - val_loss: 1.7963\n",
      "Epoch 5/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3776 - loss: 1.7587 - val_accuracy: 0.3810 - val_loss: 1.7550\n",
      "Epoch 6/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3945 - loss: 1.7154 - val_accuracy: 0.3893 - val_loss: 1.7345\n",
      "Epoch 7/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4066 - loss: 1.6858 - val_accuracy: 0.3951 - val_loss: 1.7232\n",
      "Epoch 8/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4232 - loss: 1.6482 - val_accuracy: 0.3699 - val_loss: 1.7747\n",
      "Epoch 9/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4246 - loss: 1.6360 - val_accuracy: 0.4056 - val_loss: 1.6762\n",
      "Epoch 10/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4391 - loss: 1.5972 - val_accuracy: 0.4208 - val_loss: 1.6577\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4257 - loss: 1.6431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6528210639953613, 0.41819998621940613]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu',kernel_initializer='glorot_uniform'))\n",
    "model.add(Dense(128,activation='relu',kernel_initializer='glorot_uniform'))\n",
    "model.add(Dense(10,activation='softmax',kernel_initializer='glorot_uniform'))\n",
    "sgd_optimizer=optimizers.SGD(learning_rate=0.01,momentum=0.9)\n",
    "model.compile(optimizer=sgd_optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "xav=model.fit(xtrain,ytrain,epochs=10,batch_size=128,validation_split=0.2)\n",
    "model.evaluate(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.1865 - loss: 2.1855 - val_accuracy: 0.2604 - val_loss: 2.0179\n",
      "Epoch 2/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.2854 - loss: 1.9966 - val_accuracy: 0.3179 - val_loss: 1.9212\n",
      "Epoch 3/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.3175 - loss: 1.9096 - val_accuracy: 0.3181 - val_loss: 1.8958\n",
      "Epoch 4/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.3402 - loss: 1.8575 - val_accuracy: 0.3487 - val_loss: 1.8388\n",
      "Epoch 5/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.3601 - loss: 1.8103 - val_accuracy: 0.3613 - val_loss: 1.7832\n",
      "Epoch 6/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.3732 - loss: 1.7659 - val_accuracy: 0.3495 - val_loss: 1.8259\n",
      "Epoch 7/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.3864 - loss: 1.7416 - val_accuracy: 0.3900 - val_loss: 1.7261\n",
      "Epoch 8/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3883 - loss: 1.7211 - val_accuracy: 0.3895 - val_loss: 1.7177\n",
      "Epoch 9/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.3966 - loss: 1.7006 - val_accuracy: 0.3965 - val_loss: 1.7299\n",
      "Epoch 10/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.4010 - loss: 1.6857 - val_accuracy: 0.4053 - val_loss: 1.6892\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4079 - loss: 1.6745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6822253465652466, 0.4034000039100647]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Xavier with dropout\n",
    "model_d=Sequential()\n",
    "model_d.add(Flatten())\n",
    "model_d.add(Dense(512,activation='relu',kernel_initializer='glorot_uniform'))\n",
    "model_d.add(Dropout(0.25))\n",
    "model_d.add(Dense(256,activation='relu'))\n",
    "model_d.add(Dense(10,activation='softmax'))\n",
    "sgd_optimizer=optimizers.SGD(learning_rate=0.01,momentum=0.9)\n",
    "model_d.compile(optimizer=sgd_optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "drop=model_d.fit(xtrain,ytrain,epochs=10,batch_size=128,validation_split=0.2)\n",
    "model_d.evaluate(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3154 - loss: 1.9235 - val_accuracy: 0.3749 - val_loss: 1.7605\n",
      "Epoch 2/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4270 - loss: 1.6185 - val_accuracy: 0.4071 - val_loss: 1.6691\n",
      "Epoch 3/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4718 - loss: 1.5049 - val_accuracy: 0.4036 - val_loss: 1.7374\n",
      "Epoch 4/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5030 - loss: 1.4124 - val_accuracy: 0.3955 - val_loss: 1.7689\n",
      "Epoch 5/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5247 - loss: 1.3508 - val_accuracy: 0.4032 - val_loss: 1.8820\n",
      "Epoch 6/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5474 - loss: 1.2886 - val_accuracy: 0.4271 - val_loss: 1.6575\n",
      "Epoch 7/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5703 - loss: 1.2477 - val_accuracy: 0.4103 - val_loss: 1.8200\n",
      "Epoch 8/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5760 - loss: 1.2081 - val_accuracy: 0.4550 - val_loss: 1.6227\n",
      "Epoch 9/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5918 - loss: 1.1679 - val_accuracy: 0.4364 - val_loss: 1.7487\n",
      "Epoch 10/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6063 - loss: 1.1197 - val_accuracy: 0.4306 - val_loss: 1.7776\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4345 - loss: 1.7622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7891052961349487, 0.42480000853538513]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Batch Normalization\n",
    "model_bn=Sequential()\n",
    "model_bn.add(Flatten())\n",
    "model_bn.add(Dense(256,activation='relu'))\n",
    "model_bn.add(layers.BatchNormalization())\n",
    "model_bn.add(layers.Activation('relu'))\n",
    "model_bn.add(Dense(10,activation='softmax'))\n",
    "sgd_optimizer=optimizers.SGD(learning_rate=0.01,momentum=0.9)\n",
    "model_bn.compile(optimizer=sgd_optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "drop=model_bn.fit(xtrain,ytrain,epochs=10,batch_size=32,validation_split=0.2)\n",
    "model_bn.evaluate(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
